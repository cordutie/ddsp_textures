{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !git clone https://github.com/cordutie/texstat.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FAD Resynthesis Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bubbles': [['evaluation_sounds/bubbles.wav', 'evaluation_sounds/bubbles_1.wav'], ['evaluation_sounds/bubbles.wav', 'evaluation_sounds/bubbles_2.wav'], ['evaluation_sounds/bubbles.wav', 'evaluation_sounds/bubbles_3.wav'], ['evaluation_sounds/bubbles.wav', 'evaluation_sounds/bubbles_4.wav']], 'fire': [['evaluation_sounds/fire.wav', 'evaluation_sounds/fire_1.wav'], ['evaluation_sounds/fire.wav', 'evaluation_sounds/fire_2.wav'], ['evaluation_sounds/fire.wav', 'evaluation_sounds/fire_3.wav'], ['evaluation_sounds/fire.wav', 'evaluation_sounds/fire_4.wav'], ['evaluation_sounds/fire.wav', 'evaluation_sounds/fire_5.wav']], 'keyboard': [['evaluation_sounds/keyboard.wav', 'evaluation_sounds/keyboard_1.wav']], 'rain': [['evaluation_sounds/rain.wav', 'evaluation_sounds/rain_1.wav'], ['evaluation_sounds/rain.wav', 'evaluation_sounds/rain_2.wav']], 'river': [['evaluation_sounds/river.wav', 'evaluation_sounds/river_1.wav'], ['evaluation_sounds/river.wav', 'evaluation_sounds/river_2.wav'], ['evaluation_sounds/river.wav', 'evaluation_sounds/river_3.wav']], 'shards': [['evaluation_sounds/shards.wav', 'evaluation_sounds/shards_1.wav']], 'waterfall': [['evaluation_sounds/waterfall.wav', 'evaluation_sounds/waterfall_1.wav'], ['evaluation_sounds/waterfall.wav', 'evaluation_sounds/waterfall_2.wav']], 'wind': [['evaluation_sounds/wind.wav', 'evaluation_sounds/wind_1.wav'], ['evaluation_sounds/wind.wav', 'evaluation_sounds/wind_2.wav']]}\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the parent directory to the Python path\n",
    "parent_dir = os.path.abspath('texstat/')\n",
    "if parent_dir not in sys.path:\n",
    "    sys.path.append(parent_dir)\n",
    "\n",
    "# Pairs of paths to be compared\n",
    "texture_types = [\"bubbles\", \"fire\", \"keyboard\", \"rain\", \"river\", \"shards\", \"waterfall\", \"wind\"]\n",
    "\n",
    "pairs = {}\n",
    "for texture_type in texture_types:\n",
    "    original_path = \"evaluation_sounds/\"+texture_type+\".wav\"\n",
    "    # make list of all files in evaluation_sounds/ that start with texture_type\n",
    "    reproductions = [\"evaluation_sounds/\"+reproduction for reproduction in os.listdir(\"evaluation_sounds/\") if reproduction.startswith(texture_type)]\n",
    "    # list of pairs [original_path, reproduction_path]\n",
    "    pairs[texture_type] = []\n",
    "    for reproduction in reproductions:\n",
    "        if reproduction != original_path:\n",
    "            pairs[texture_type].append([original_path, reproduction])\n",
    "    # sort\n",
    "    pairs[texture_type].sort(key=lambda x: x[1])\n",
    "\n",
    "print(pairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. FAD using TexStat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texture type:  bubbles\n",
      "Segmented 120 segments from signal\n",
      "Processed 120 segments from signal\n",
      "Segmented 119 segments from signal\n",
      "Processed 119 segments from signal\n",
      "FAD score for pair:  evaluation_sounds/bubbles.wav evaluation_sounds/bubbles_1.wav is 1138.8335603029718\n",
      "Segmented 120 segments from signal\n",
      "Processed 120 segments from signal\n",
      "Segmented 118 segments from signal\n",
      "Processed 118 segments from signal\n",
      "FAD score for pair:  evaluation_sounds/bubbles.wav evaluation_sounds/bubbles_2.wav is 83.805898021874\n",
      "Segmented 120 segments from signal\n",
      "Processed 120 segments from signal\n",
      "Segmented 118 segments from signal\n",
      "Processed 118 segments from signal\n",
      "FAD score for pair:  evaluation_sounds/bubbles.wav evaluation_sounds/bubbles_3.wav is 63.7318939554856\n",
      "Segmented 120 segments from signal\n",
      "Processed 120 segments from signal\n",
      "Segmented 119 segments from signal\n",
      "Processed 119 segments from signal\n",
      "FAD score for pair:  evaluation_sounds/bubbles.wav evaluation_sounds/bubbles_4.wav is 90.91121753775059\n",
      "Texture type:  fire\n",
      "Segmented 120 segments from signal\n",
      "Processed 120 segments from signal\n",
      "Segmented 119 segments from signal\n",
      "Processed 119 segments from signal\n",
      "FAD score for pair:  evaluation_sounds/fire.wav evaluation_sounds/fire_1.wav is 570.174902405157\n",
      "Segmented 120 segments from signal\n",
      "Processed 120 segments from signal\n",
      "Segmented 119 segments from signal\n",
      "Processed 119 segments from signal\n",
      "FAD score for pair:  evaluation_sounds/fire.wav evaluation_sounds/fire_2.wav is 617.9510814629098\n",
      "Segmented 120 segments from signal\n",
      "Processed 120 segments from signal\n",
      "Segmented 119 segments from signal\n",
      "Processed 119 segments from signal\n",
      "FAD score for pair:  evaluation_sounds/fire.wav evaluation_sounds/fire_3.wav is 634.9888745842063\n",
      "Segmented 120 segments from signal\n",
      "Processed 120 segments from signal\n",
      "Segmented 119 segments from signal\n",
      "Processed 119 segments from signal\n",
      "FAD score for pair:  evaluation_sounds/fire.wav evaluation_sounds/fire_4.wav is 626.9264184560196\n",
      "Segmented 120 segments from signal\n",
      "Processed 120 segments from signal\n",
      "Segmented 119 segments from signal\n",
      "Processed 119 segments from signal\n",
      "FAD score for pair:  evaluation_sounds/fire.wav evaluation_sounds/fire_5.wav is 825.1842281846001\n",
      "Texture type:  keyboard\n",
      "Segmented 120 segments from signal\n",
      "Processed 120 segments from signal\n",
      "Segmented 119 segments from signal\n",
      "Processed 119 segments from signal\n",
      "FAD score for pair:  evaluation_sounds/keyboard.wav evaluation_sounds/keyboard_1.wav is 1945.6852428469756\n",
      "Texture type:  rain\n",
      "Segmented 120 segments from signal\n",
      "Processed 120 segments from signal\n",
      "Segmented 118 segments from signal\n",
      "Processed 118 segments from signal\n",
      "FAD score for pair:  evaluation_sounds/rain.wav evaluation_sounds/rain_1.wav is 36.59688539360174\n",
      "Segmented 120 segments from signal\n",
      "Processed 120 segments from signal\n",
      "Segmented 119 segments from signal\n",
      "Processed 119 segments from signal\n",
      "FAD score for pair:  evaluation_sounds/rain.wav evaluation_sounds/rain_2.wav is 38.37135280135271\n",
      "Texture type:  river\n",
      "Segmented 120 segments from signal\n",
      "Processed 120 segments from signal\n",
      "Segmented 119 segments from signal\n",
      "Processed 119 segments from signal\n",
      "FAD score for pair:  evaluation_sounds/river.wav evaluation_sounds/river_1.wav is 43.03603162858988\n",
      "Segmented 120 segments from signal\n",
      "Processed 120 segments from signal\n",
      "Segmented 119 segments from signal\n",
      "Processed 119 segments from signal\n",
      "FAD score for pair:  evaluation_sounds/river.wav evaluation_sounds/river_2.wav is 43.753029822653325\n",
      "Segmented 120 segments from signal\n",
      "Processed 120 segments from signal\n",
      "Segmented 119 segments from signal\n",
      "Processed 119 segments from signal\n",
      "FAD score for pair:  evaluation_sounds/river.wav evaluation_sounds/river_3.wav is 38.076804045774054\n",
      "Texture type:  shards\n",
      "Segmented 120 segments from signal\n",
      "Processed 120 segments from signal\n",
      "Segmented 118 segments from signal\n",
      "Processed 118 segments from signal\n",
      "FAD score for pair:  evaluation_sounds/shards.wav evaluation_sounds/shards_1.wav is 8.103301143718397\n",
      "Texture type:  waterfall\n",
      "Segmented 120 segments from signal\n",
      "Processed 120 segments from signal\n",
      "Segmented 119 segments from signal\n",
      "Processed 119 segments from signal\n",
      "FAD score for pair:  evaluation_sounds/waterfall.wav evaluation_sounds/waterfall_1.wav is 28.418002170714935\n",
      "Segmented 120 segments from signal\n",
      "Processed 120 segments from signal\n",
      "Segmented 119 segments from signal\n",
      "Processed 119 segments from signal\n",
      "FAD score for pair:  evaluation_sounds/waterfall.wav evaluation_sounds/waterfall_2.wav is 28.362404615197203\n",
      "Texture type:  wind\n",
      "Segmented 120 segments from signal\n",
      "Processed 120 segments from signal\n",
      "Segmented 119 segments from signal\n",
      "Processed 119 segments from signal\n",
      "FAD score for pair:  evaluation_sounds/wind.wav evaluation_sounds/wind_1.wav is 244.74377675218162\n",
      "Segmented 120 segments from signal\n",
      "Processed 120 segments from signal\n",
      "Segmented 119 segments from signal\n",
      "Processed 119 segments from signal\n",
      "FAD score for pair:  evaluation_sounds/wind.wav evaluation_sounds/wind_2.wav is 398.947126424758\n"
     ]
    }
   ],
   "source": [
    "from texstat.fad import *\n",
    "import texstat.torch_filterbanks.filterbanks as fb\n",
    "import librosa\n",
    "import torchaudio\n",
    "\n",
    "# texstat properties\n",
    "sr            = 44100\n",
    "frame_size    = 44100\n",
    "N_filter_bank = 16\n",
    "M_filter_bank = 6\n",
    "new_sr, new_frame_size = sr // 4, frame_size // 4 # for downsampler\n",
    "downsampler = torchaudio.transforms.Resample(sr, new_sr)\n",
    "coch_fb     = fb.EqualRectangularBandwidth(frame_size, sr, N_filter_bank, 20, sr // 2)\n",
    "mod_fb      = fb.Logarithmic(new_frame_size,       new_sr, M_filter_bank, 10, new_sr // 4)\n",
    "\n",
    "for texture_type in texture_types:\n",
    "    print(\"Texture type: \", texture_type)\n",
    "    for pair in pairs[texture_type]:\n",
    "        original_path       = pair[0]\n",
    "        original_signal     = librosa.load(original_path, sr=44100, mono=True)[0]\n",
    "        reproduction_path   = pair[1]\n",
    "        reproduction_signal = librosa.load(reproduction_path, sr=44100, mono=True)[0]\n",
    "        # Compute the FAD\n",
    "        fad = compute_fad_from_signals(original_signal, reproduction_signal, frame_size, coch_fb, mod_fb, downsampler)\n",
    "        print(\"FAD score for pair: \", original_path, reproduction_path, \"is\", fad)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. FAD using VGGish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texture type:  bubbles\n",
      "FAD score for pair:  evaluation_sounds/bubbles.wav evaluation_sounds/bubbles_1.wav is 1134844.7413896786\n",
      "FAD score for pair:  evaluation_sounds/bubbles.wav evaluation_sounds/bubbles_2.wav is 1123190.9084297614\n",
      "FAD score for pair:  evaluation_sounds/bubbles.wav evaluation_sounds/bubbles_3.wav is 1021556.0924389309\n",
      "FAD score for pair:  evaluation_sounds/bubbles.wav evaluation_sounds/bubbles_4.wav is 1562180.8857099612\n",
      "Texture type:  fire\n",
      "FAD score for pair:  evaluation_sounds/fire.wav evaluation_sounds/fire_1.wav is 765102.6467977822\n",
      "FAD score for pair:  evaluation_sounds/fire.wav evaluation_sounds/fire_2.wav is 726847.7355396337\n",
      "FAD score for pair:  evaluation_sounds/fire.wav evaluation_sounds/fire_3.wav is 765337.581345021\n",
      "FAD score for pair:  evaluation_sounds/fire.wav evaluation_sounds/fire_4.wav is 701855.4972806366\n",
      "FAD score for pair:  evaluation_sounds/fire.wav evaluation_sounds/fire_5.wav is 772594.884657207\n",
      "Texture type:  keyboard\n",
      "FAD score for pair:  evaluation_sounds/keyboard.wav evaluation_sounds/keyboard_1.wav is 822501.3195850179\n",
      "Texture type:  rain\n",
      "FAD score for pair:  evaluation_sounds/rain.wav evaluation_sounds/rain_1.wav is 763469.464219195\n",
      "FAD score for pair:  evaluation_sounds/rain.wav evaluation_sounds/rain_2.wav is 711639.5268442892\n",
      "Texture type:  river\n",
      "FAD score for pair:  evaluation_sounds/river.wav evaluation_sounds/river_1.wav is 1206077.1191599471\n",
      "FAD score for pair:  evaluation_sounds/river.wav evaluation_sounds/river_2.wav is 1241060.5607840975\n",
      "FAD score for pair:  evaluation_sounds/river.wav evaluation_sounds/river_3.wav is 1321267.745201578\n",
      "Texture type:  shards\n",
      "FAD score for pair:  evaluation_sounds/shards.wav evaluation_sounds/shards_1.wav is 306450.92121499364\n",
      "Texture type:  waterfall\n",
      "FAD score for pair:  evaluation_sounds/waterfall.wav evaluation_sounds/waterfall_1.wav is 745963.6555954308\n",
      "FAD score for pair:  evaluation_sounds/waterfall.wav evaluation_sounds/waterfall_2.wav is 723389.1384225037\n",
      "Texture type:  wind\n",
      "FAD score for pair:  evaluation_sounds/wind.wav evaluation_sounds/wind_1.wav is 520621.78288598056\n",
      "FAD score for pair:  evaluation_sounds/wind.wav evaluation_sounds/wind_2.wav is 537268.6242163831\n"
     ]
    }
   ],
   "source": [
    "from torchvggish import vggish, vggish_input\n",
    "\n",
    "# Initialise model and download weights\n",
    "embedding_model = vggish()\n",
    "embedding_model.eval()\n",
    "\n",
    "for texture_type in texture_types:\n",
    "    print(\"Texture type: \", texture_type)\n",
    "    for pair in pairs[texture_type]:\n",
    "        original_path       = pair[0]\n",
    "        original_preprocessed = vggish_input.wavfile_to_examples(original_path)\n",
    "        original_embeddings   = embedding_model.forward(original_preprocessed).detach().numpy()\n",
    "        reproduction_path   = pair[1]\n",
    "        reproduction_preprocessed = vggish_input.wavfile_to_examples(reproduction_path)\n",
    "        reproduction_embeddings = embedding_model.forward(reproduction_preprocessed).detach().numpy()\n",
    "        # Compute the FAD\n",
    "        fad = compute_fad_from_embeddings(original_embeddings, reproduction_embeddings)\n",
    "        print(\"FAD score for pair: \", original_path, reproduction_path, \"is\", fad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. TexStat and MSS frame-by-frame score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texture type:  bubbles\n",
      "Pair:  ['evaluation_sounds/bubbles.wav', 'evaluation_sounds/bubbles_1.wav']\n",
      "Stats loss mean ± std: $1.3 \\pm 0.3$\n",
      "MSS loss mean ± std: $7.9 \\pm 0.7$\n",
      "Pair:  ['evaluation_sounds/bubbles.wav', 'evaluation_sounds/bubbles_2.wav']\n",
      "Stats loss mean ± std: $1.4 \\pm 0.3$\n",
      "MSS loss mean ± std: $7.4 \\pm 0.5$\n",
      "Pair:  ['evaluation_sounds/bubbles.wav', 'evaluation_sounds/bubbles_3.wav']\n",
      "Stats loss mean ± std: $1.2 \\pm 0.3$\n",
      "MSS loss mean ± std: $6.6 \\pm 0.3$\n",
      "Pair:  ['evaluation_sounds/bubbles.wav', 'evaluation_sounds/bubbles_4.wav']\n",
      "Stats loss mean ± std: $1.5 \\pm 0.3$\n",
      "MSS loss mean ± std: $8.1 \\pm 0.5$\n",
      "Texture type:  fire\n",
      "Pair:  ['evaluation_sounds/fire.wav', 'evaluation_sounds/fire_1.wav']\n",
      "Stats loss mean ± std: $2.9 \\pm 2.0$\n",
      "MSS loss mean ± std: $10.1 \\pm 1.2$\n",
      "Pair:  ['evaluation_sounds/fire.wav', 'evaluation_sounds/fire_2.wav']\n",
      "Stats loss mean ± std: $2.9 \\pm 2.1$\n",
      "MSS loss mean ± std: $9.6 \\pm 1.3$\n",
      "Pair:  ['evaluation_sounds/fire.wav', 'evaluation_sounds/fire_3.wav']\n",
      "Stats loss mean ± std: $2.8 \\pm 2.2$\n",
      "MSS loss mean ± std: $10.3 \\pm 1.5$\n",
      "Pair:  ['evaluation_sounds/fire.wav', 'evaluation_sounds/fire_4.wav']\n",
      "Stats loss mean ± std: $2.8 \\pm 2.2$\n",
      "MSS loss mean ± std: $10.4 \\pm 1.6$\n",
      "Pair:  ['evaluation_sounds/fire.wav', 'evaluation_sounds/fire_5.wav']\n",
      "Stats loss mean ± std: $3.4 \\pm 2.6$\n",
      "MSS loss mean ± std: $12.7 \\pm 2.4$\n",
      "Texture type:  keyboard\n",
      "Pair:  ['evaluation_sounds/keyboard.wav', 'evaluation_sounds/keyboard_1.wav']\n",
      "Stats loss mean ± std: $5.7 \\pm 2.0$\n",
      "MSS loss mean ± std: $9.1 \\pm 0.7$\n",
      "Texture type:  rain\n",
      "Pair:  ['evaluation_sounds/rain.wav', 'evaluation_sounds/rain_1.wav']\n",
      "Stats loss mean ± std: $0.5 \\pm 0.2$\n",
      "MSS loss mean ± std: $9.5 \\pm 0.3$\n",
      "Pair:  ['evaluation_sounds/rain.wav', 'evaluation_sounds/rain_2.wav']\n",
      "Stats loss mean ± std: $0.5 \\pm 0.2$\n",
      "MSS loss mean ± std: $9.0 \\pm 0.2$\n",
      "Texture type:  river\n",
      "Pair:  ['evaluation_sounds/river.wav', 'evaluation_sounds/river_1.wav']\n",
      "Stats loss mean ± std: $0.5 \\pm 0.1$\n",
      "MSS loss mean ± std: $7.7 \\pm 0.8$\n",
      "Pair:  ['evaluation_sounds/river.wav', 'evaluation_sounds/river_2.wav']\n",
      "Stats loss mean ± std: $0.5 \\pm 0.1$\n",
      "MSS loss mean ± std: $6.5 \\pm 0.7$\n",
      "Pair:  ['evaluation_sounds/river.wav', 'evaluation_sounds/river_3.wav']\n",
      "Stats loss mean ± std: $0.5 \\pm 0.1$\n",
      "MSS loss mean ± std: $6.0 \\pm 0.6$\n",
      "Texture type:  shards\n",
      "Pair:  ['evaluation_sounds/shards.wav', 'evaluation_sounds/shards_1.wav']\n",
      "Stats loss mean ± std: $1.0 \\pm 0.2$\n",
      "MSS loss mean ± std: $7.9 \\pm 0.2$\n",
      "Texture type:  waterfall\n",
      "Pair:  ['evaluation_sounds/waterfall.wav', 'evaluation_sounds/waterfall_1.wav']\n",
      "Stats loss mean ± std: $0.3 \\pm 0.0$\n",
      "MSS loss mean ± std: $5.0 \\pm 0.0$\n",
      "Pair:  ['evaluation_sounds/waterfall.wav', 'evaluation_sounds/waterfall_2.wav']\n",
      "Stats loss mean ± std: $0.3 \\pm 0.0$\n",
      "MSS loss mean ± std: $5.0 \\pm 0.0$\n",
      "Texture type:  wind\n",
      "Pair:  ['evaluation_sounds/wind.wav', 'evaluation_sounds/wind_1.wav']\n",
      "Stats loss mean ± std: $0.8 \\pm 0.5$\n",
      "MSS loss mean ± std: $5.6 \\pm 0.1$\n",
      "Pair:  ['evaluation_sounds/wind.wav', 'evaluation_sounds/wind_2.wav']\n",
      "Stats loss mean ± std: $0.8 \\pm 0.6$\n",
      "MSS loss mean ± std: $5.5 \\pm 0.1$\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the parent directory to the Python path\n",
    "parent_dir = os.path.abspath('texstat/')\n",
    "if parent_dir not in sys.path:\n",
    "    sys.path.append(parent_dir)\n",
    "    \n",
    "from texstat.segmentation import *\n",
    "from texstat.functions import *\n",
    "import torch\n",
    "from texstat.fad import *\n",
    "import texstat.torch_filterbanks.filterbanks as fb\n",
    "import librosa\n",
    "import torchaudio\n",
    "\n",
    "# Multiscale Spectrogram Loss for comparison\n",
    "def multiscale_fft(signal, scales=[4096, 2048, 1024, 512, 256, 128], overlap=.75):\n",
    "    stfts = []\n",
    "    for s in scales:\n",
    "        S = torch.stft(\n",
    "            signal,\n",
    "            s,\n",
    "            int(s * (1 - overlap)),\n",
    "            s,\n",
    "            torch.hann_window(s).to(signal),\n",
    "            True,\n",
    "            normalized=True,\n",
    "            return_complex=True,\n",
    "        ).abs()\n",
    "        stfts.append(S)\n",
    "    return stfts\n",
    "\n",
    "def safe_log(x):\n",
    "    return torch.log(x + 1e-7)\n",
    "\n",
    "def multiscale_spectrogram_loss(x, x_hat):\n",
    "    ori_stft = multiscale_fft(x)\n",
    "    rec_stft = multiscale_fft(x_hat)\n",
    "    loss = 0\n",
    "    for s_x, s_y in zip(ori_stft, rec_stft):\n",
    "        lin_loss = (s_x - s_y).abs().mean()\n",
    "        log_loss = (safe_log(s_x) - safe_log(s_y)).abs().mean()\n",
    "        loss = loss + lin_loss + log_loss\n",
    "    return loss\n",
    "\n",
    "# TexStat parameters\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "sr            = 44100\n",
    "frame_size    = sr\n",
    "N_filter_bank = 16\n",
    "M_filter_bank = 6\n",
    "N_moments     = 4\n",
    "alpha         = torch.tensor([10, 1, 1/10, 1/100], device=device)\n",
    "beta          = torch.tensor([1, 1, 1, 1, 1], device=device) \n",
    "new_sr, new_frame_size = sr // 4, frame_size // 4 # for downsampler\n",
    "downsampler = torchaudio.transforms.Resample(sr, new_sr).to(device)\n",
    "coch_fb     = fb.EqualRectangularBandwidth(frame_size, sr, N_filter_bank, 20, sr // 2)\n",
    "mod_fb      = fb.Logarithmic(new_frame_size,       new_sr, M_filter_bank, 10, new_sr // 4)\n",
    "\n",
    "\n",
    "for texture_type in texture_types:\n",
    "    print(\"Texture type: \", texture_type)\n",
    "    for pair in pairs[texture_type]:\n",
    "        print(\"Pair: \", pair)\n",
    "        original_path         = pair[0]\n",
    "        original_segments     = segment_audio(original_path, sr, sr, torch_type=True)\n",
    "        reproduction_path     = pair[1]\n",
    "        reproduction_segments = segment_audio(reproduction_path, sr, sr, torch_type=True)\n",
    "        min_segments = min(len(original_segments), len(reproduction_segments))\n",
    "        stats_loss = []\n",
    "        mss_loss   = []\n",
    "        for i in range(min_segments):\n",
    "            og   = original_segments[i].to(device)\n",
    "            fake = reproduction_segments[i].to(device)\n",
    "            stats_loss_local = texstat_loss(og, fake, coch_fb, mod_fb, downsampler, N_moments, alpha, beta)\n",
    "            mss_loss_local   = multiscale_spectrogram_loss(og, fake)\n",
    "            stats_loss.append(stats_loss_local)  # Convert to scalar\n",
    "            mss_loss.append(mss_loss_local)\n",
    "        # torch stack\n",
    "        stats_loss = torch.stack(stats_loss)\n",
    "        mss_loss   = torch.stack(mss_loss)\n",
    "        # Report mean and std\n",
    "        stats_loss_mean = stats_loss.mean().item()\n",
    "        stats_loss_std  = stats_loss.std().item()\n",
    "        mss_loss_mean   = mss_loss.mean().item()\n",
    "        mss_loss_std    = mss_loss.std().item()\n",
    "        # Report\n",
    "        print(f\"Stats loss mean ± std: ${stats_loss_mean:.1f} \\\\pm {stats_loss_std:.1f}$\")\n",
    "        print(f\"MSS loss mean ± std: ${mss_loss_mean:.1f} \\\\pm {mss_loss_std:.1f}$\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_ddsp_textures",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
