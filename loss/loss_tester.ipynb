{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the parent directory to the Python path\n",
    "parent_dir = os.path.abspath('../..')\n",
    "if parent_dir not in sys.path:\n",
    "    sys.path.append(parent_dir)\n",
    "\n",
    "# Import modules\n",
    "import ddsp_textures.loss.functions\n",
    "import ddsp_textures.auxiliar.filterbanks\n",
    "\n",
    "# Import extra packages\n",
    "import numpy as np\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Audio\n",
    "import torch\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fire statistics:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Fire statistics:\\n\")\n",
    "names = [\"stats_11\", \"stats_12\", \"stats_13\", \"stats_14\", \"stats_2\", \"stats_3\", \"stats_4\", \"stats_5\"]\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Load audio to filter -----------------------------------\n",
    "fire_path  = \"..\"+\"/sounds/fire_sounds/fire.wav\"\n",
    "water_path = \"..\"+\"/sounds/water_sounds/water.wav\"\n",
    "sr     = 44100\n",
    "new_sr = sr // 4 # for log_bank\n",
    "fire_audio, _  = librosa.load(fire_path, sr=sr)\n",
    "fire_audio = fire_audio/np.max(np.abs(fire_audio))\n",
    "water_audio, _ = librosa.load(water_path, sr=sr)\n",
    "water_audio = water_audio/np.max(np.abs(water_audio))\n",
    "# Make list of segments for fire and water --------------\n",
    "frame_size     = 2**15\n",
    "new_frame_size = frame_size // 4\n",
    "hop_size   = 2**15\n",
    "fire_segments = []\n",
    "water_segments = []\n",
    "for i in range(0, len(fire_audio)-frame_size, hop_size):\n",
    "    # segment_norm = (fire_audio[i:i+frame_size] - np.mean(fire_audio[i:i+frame_size])) / np.std(fire_audio[i:i+frame_size])\n",
    "    segment = fire_audio[i:i+frame_size]\n",
    "    fire_segments.append(segment)\n",
    "for i in range(0, len(water_audio)-frame_size, hop_size):\n",
    "    # segment_norm = (water_audio[i:i+frame_size] - np.mean(water_audio[i:i+frame_size])) / np.std(water_audio[i:i+frame_size])\n",
    "    segment = water_audio[i:i+frame_size]\n",
    "    water_segments.append(segment)\n",
    "# Initialize erb_bank and log_bank for statistics loss --\n",
    "N_filter_bank = 16\n",
    "M_filter_bank = 6\n",
    "erb_bank    = ddsp_textures.auxiliar.filterbanks.EqualRectangularBandwidth(frame_size, sr, N_filter_bank, 20, sr // 2)\n",
    "log_bank    = ddsp_textures.auxiliar.filterbanks.Logarithmic(new_frame_size,       new_sr, M_filter_bank, 10, new_sr // 4)\n",
    "\n",
    "import torchaudio\n",
    "downsampler = torchaudio.transforms.Resample(sr, new_sr).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difference in stats 0 tensor(9.0122e-05, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "Difference in stats 1 tensor(2.3305e-05, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "Difference in stats 2 tensor(8.9407e-08, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "Difference in stats 3 tensor(0.0001, device='cuda:0', grad_fn=<MaxBackward1>)\n",
      "Difference in stats 4 tensor(6.8784e-05, device='cuda:0', grad_fn=<MaxBackward1>)\n"
     ]
    }
   ],
   "source": [
    "#Testing Statistics functions --------------------------------------------------\n",
    "fire_segment = fire_segments[0]\n",
    "\n",
    "# create tensor with req gra\n",
    "input_tensor = torch.tensor(fire_segment, requires_grad=True).to(device)\n",
    "output_1 = ddsp_textures.loss.functions.statistics_mcds(      input_tensor, N_filter_bank, M_filter_bank, erb_bank, log_bank, downsampler)\n",
    "output_2 = ddsp_textures.loss.functions.statistics_mcds_old(  input_tensor, N_filter_bank, M_filter_bank, erb_bank, log_bank, downsampler)\n",
    "\n",
    "# Compare gradients for each tensor in the list\n",
    "for i in range(5):\n",
    "    print(\"Difference in stats\", i, (torch.sort(output_1[i].flatten()).values - torch.sort(output_2[i].flatten()).values).abs().max())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stats_1_mean:  tensor(18.4363, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "stats_2_mean:  tensor(-0.0088, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "stats_3_mean:  tensor(0.3259, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "stats_4_mean:  tensor(-0.0103, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "stats_5_mean:  tensor(0.1067, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "grad  stats_11 :  tensor([-1.2133e-03,  1.1966e-03,  1.7662e-03,  ..., -3.4601e-04,\n",
      "        -1.7098e-03, -9.6810e-05], device='cuda:0', dtype=torch.float64)\n",
      "grad  stats_12 :  tensor([1.8123e-05, 4.2602e-05, 6.1529e-05,  ..., 4.9376e-05, 6.4953e-05,\n",
      "        3.7321e-05], device='cuda:0', dtype=torch.float64)\n",
      "grad  stats_13 :  tensor([8.7516e-05, 4.3566e-05, 4.0512e-05,  ..., 6.2467e-05, 9.4924e-05,\n",
      "        4.2309e-05], device='cuda:0', dtype=torch.float64)\n",
      "grad  stats_14 :  tensor([ 3.2572e-04, -1.0719e-04, -9.1848e-05,  ..., -1.0835e-04,\n",
      "         2.6639e-04, -7.0325e-05], device='cuda:0', dtype=torch.float64)\n",
      "grad  stats_2 :  tensor([-7.8264e-05, -4.2841e-05, -1.3139e-05,  ..., -4.1560e-05,\n",
      "        -7.4877e-05, -4.8364e-05], device='cuda:0', dtype=torch.float64)\n",
      "Time:  0.1778557300567627\n",
      "grad  stats_11 :  tensor([-1.2133e-03,  1.1966e-03,  1.7662e-03,  ..., -3.4601e-04,\n",
      "        -1.7098e-03, -9.6811e-05], device='cuda:0', dtype=torch.float64)\n",
      "grad  stats_12 :  tensor([1.8123e-05, 4.2600e-05, 6.1528e-05,  ..., 4.9374e-05, 6.4951e-05,\n",
      "        3.7320e-05], device='cuda:0', dtype=torch.float64)\n",
      "grad  stats_13 :  tensor([8.7516e-05, 4.3566e-05, 4.0512e-05,  ..., 6.2467e-05, 9.4924e-05,\n",
      "        4.2309e-05], device='cuda:0', dtype=torch.float64)\n",
      "grad  stats_14 :  tensor([ 3.2568e-04, -1.0718e-04, -9.1835e-05,  ..., -1.0833e-04,\n",
      "         2.6636e-04, -7.0316e-05], device='cuda:0', dtype=torch.float64)\n",
      "grad  stats_2 :  tensor([-7.8255e-05, -4.2836e-05, -1.3138e-05,  ..., -4.1555e-05,\n",
      "        -7.4868e-05, -4.8358e-05], device='cuda:0', dtype=torch.float64)\n",
      "Time:  0.35643815994262695\n"
     ]
    }
   ],
   "source": [
    "#Testing Statistics functions --------------------------------------------------\n",
    "fire_segment   = fire_segments[0]\n",
    "fire_segment = np.random.rand(len(fire_segment))\n",
    "x_1 = torch.tensor(fire_segment, requires_grad=True).to(device)\n",
    "x_2 = torch.tensor(fire_segment, requires_grad=True).to(device)\n",
    "\n",
    "# x_1\n",
    "stats_1, stats_2, stats_3, stats_4, stats_5 = ddsp_textures.loss.functions.statistics_mcds(x_1, N_filter_bank, M_filter_bank, erb_bank, log_bank, downsampler)\n",
    "\n",
    "stats_1_mean = torch.mean(stats_1)\n",
    "print(\"stats_1_mean: \", stats_1_mean)\n",
    "stats_2_mean = torch.mean(stats_2)\n",
    "print(\"stats_2_mean: \", stats_2_mean)\n",
    "stats_3_mean = torch.mean(stats_3)\n",
    "print(\"stats_3_mean: \", stats_3_mean)\n",
    "stats_4_mean = torch.mean(stats_4)\n",
    "print(\"stats_4_mean: \", stats_4_mean)\n",
    "stats_5_mean = torch.mean(stats_5)\n",
    "print(\"stats_5_mean: \", stats_5_mean)\n",
    "\n",
    "y = [stats_1_mean, stats_2_mean, stats_3_mean, stats_4_mean, stats_5_mean]\n",
    "\n",
    "#compute time\n",
    "start = time.time()\n",
    "# Compute gradients for each output element separately\n",
    "for j in range(len(y)):\n",
    "    # For each y[j], compute gradient and retain graph for subsequent iterations\n",
    "    grad = torch.autograd.grad(y[j], x_1, retain_graph=True)[0]\n",
    "    print(\"grad \",names[j],\": \", grad)\n",
    "end = time.time()\n",
    "print(\"Time: \", end-start)\n",
    "\n",
    "stats_1, stats_2, stats_3, stats_4, stats_5 = ddsp_textures.loss.functions.statistics_mcds_old(x_2, N_filter_bank, M_filter_bank, erb_bank, log_bank, downsampler)\n",
    "\n",
    "stats_1_mean = torch.mean(stats_1)\n",
    "stats_2_mean = torch.mean(stats_2)\n",
    "stats_3_mean = torch.mean(stats_3)\n",
    "stats_4_mean = torch.mean(stats_4)\n",
    "stats_5_mean = torch.mean(stats_5)\n",
    "\n",
    "y = [stats_1_mean, stats_2_mean, stats_3_mean, stats_4_mean, stats_5_mean]\n",
    "\n",
    "#compute time\n",
    "start = time.time()\n",
    "# Compute gradients for each output element separately\n",
    "for j in range(len(y)):\n",
    "    # For each y[j], compute gradient and retain graph for subsequent iterations\n",
    "    grad = torch.autograd.grad(y[j], x_2, retain_graph=True)[0]\n",
    "    print(\"grad \",names[j],\": \", grad)\n",
    "end = time.time()\n",
    "print(\"Time: \", end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time new:  0.08807706832885742\n",
      "Time old:  2.1002843379974365\n",
      "Loss new:  tensor(1095.9083, device='cuda:0')\n",
      "Loss old:  tensor(1095.9072, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "batch_size = 5\n",
    "batch_example_1 = torch.zeros(batch_size, frame_size).to(device)\n",
    "for i in range(batch_size):\n",
    "    batch_example_1[i] = torch.tensor(100*fire_segments[np.random.randint(len(fire_segments))]).to(device)\n",
    "\n",
    "batch_example_2 = torch.zeros(batch_size, frame_size).to(device)\n",
    "for i in range(batch_size):\n",
    "    batch_example_2[i] = torch.tensor(100*water_segments[np.random.randint(len(water_segments))]).to(device)\n",
    "\n",
    "start=time.time()\n",
    "loss_new = ddsp_textures.loss.functions.statistics_mcds_loss(    batch_example_1, batch_example_2, N_filter_bank, M_filter_bank, erb_bank, log_bank, downsampler).to(device)\n",
    "print(\"Time new: \", time.time()-start)\n",
    "start=time.time()\n",
    "loss_old = ddsp_textures.loss.functions.statistics_mcds_loss_old(batch_example_1, batch_example_2, N_filter_bank, M_filter_bank, erb_bank, log_bank, downsampler).to(device)\n",
    "print(\"Time old: \", time.time()-start)\n",
    "\n",
    "print(\"Loss new: \", loss_new)\n",
    "print(\"Loss old: \", loss_old)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "\n",
    "# def f(x):\n",
    "#     y = torch.stack([x, x**2, x**3])\n",
    "#     return y\n",
    "\n",
    "# x = torch.tensor(5., requires_grad=True)\n",
    "# y = f(x)\n",
    "\n",
    "# # Compute gradients for each output element separately\n",
    "# gradients = []\n",
    "# for j in range(len(y)):\n",
    "#     # For each y[j], compute gradient and retain graph for subsequent iterations\n",
    "#     grad = torch.autograd.grad(y[j], x, retain_graph=True)[0]\n",
    "#     gradients.append(grad)\n",
    "\n",
    "# # Convert list of gradients to a tensor\n",
    "# dy_dx = torch.tensor(gradients)\n",
    "\n",
    "# print(dy_dx)  # Output: tensor([ 1., 10., 75.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "\n",
    "# def f(x):\n",
    "#     return x  # Identity function: f(x) = [x₁, x₂, x₃]\n",
    "\n",
    "# # Vector input with 3 elements\n",
    "# x = torch.tensor([1., 2., 3.], requires_grad=True)\n",
    "# y = f(x)\n",
    "\n",
    "# # Compute gradients for each output y_j = x_j\n",
    "# gradients = []\n",
    "# for j in range(len(y)):\n",
    "#     # Compute gradient of y[j] w.r.t x (vector input)\n",
    "#     grad = torch.autograd.grad(y[j], x, retain_graph=True)[0]\n",
    "#     gradients.append(grad)\n",
    "\n",
    "# # Stack gradients to form the Jacobian matrix\n",
    "# jacobian = torch.stack(gradients)\n",
    "\n",
    "# print(jacobian)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_ddsp_textures",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
