{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the grand-parent directory to the Python path\n",
    "parent_dir = os.path.abspath('../..')\n",
    "if parent_dir not in sys.path:\n",
    "    sys.path.append(parent_dir)\n",
    "\n",
    "# Import modules\n",
    "import ddsp_textures.signal_processors.synthesizers\n",
    "import ddsp_textures.auxiliar.seeds\n",
    "\n",
    "# Import extra packages\n",
    "import numpy as np\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Audio\n",
    "import torch\n",
    "\n",
    "# Resysnthesis function\n",
    "def resynthesize_and_display(segments, sr, seed, N_filter_bank, frame_size, param_per_env, label, N):\n",
    "    for _ in range(N):\n",
    "        # segment = segments[np.random.randint(len(segments))]\n",
    "        segment = segments[10*_]\n",
    "        segment = torch.tensor(segment, dtype=torch.float32)\n",
    "        segment = (segment-torch.mean(segment))/torch.std(segment)\n",
    "        param_real, param_imag = ddsp_textures.signal_processors.synthesizers.TexEnv_param_extractor(segment, sr, N_filter_bank, param_per_env)\n",
    "        new_audio              = ddsp_textures.signal_processors.synthesizers.TexEnv(param_real, param_imag, seed)\n",
    "        print(f\"{label} original audio\")\n",
    "        display(Audio(data=segment.numpy(), rate=sr))\n",
    "        print(f\"{label} resynthesized audio\")\n",
    "        display(Audio(data=new_audio.numpy(), rate=sr))\n",
    "        # plot both audios together\n",
    "        plt.figure()\n",
    "        plt.plot(segment.numpy(), label=\"original\")\n",
    "        plt.plot(new_audio.numpy(), label=\"resynthesized\")\n",
    "        plt.legend()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from   ddsp_textures.auxiliar.seeds import *\n",
    "\n",
    "def env_computer(signal, fs, N_filter_bank, param_per_env):\n",
    "    # send error if param_per_env is not even\n",
    "    if param_per_env % 2 != 0:\n",
    "        raise ValueError(\"param_per_env must be an even number (cause these are complex numbers).\")\n",
    "    low_lim, high_lim = 20, fs / 2  # Low limit of filter\n",
    "    size = signal.size(0)\n",
    "    \n",
    "    # Assuming fb.EqualRectangularBandwidth works with torch tensors\n",
    "    erb_bank = ddsp_textures.auxiliar.filterbanks.EqualRectangularBandwidth(size, fs, N_filter_bank, low_lim, high_lim)\n",
    "    subbands = erb_bank.generate_subbands(signal)  # generate subbands for signal y\n",
    "    \n",
    "    erb_subbands = subbands[1:-1, :].clone().to(dtype=torch.float32).detach()\n",
    "    erb_envs = torch.abs(hilbert(erb_subbands))\n",
    "\n",
    "    for i in range(N_filter_bank):\n",
    "        #plot both erb_subbands and erb_envs\n",
    "        plt.figure()\n",
    "        plt.plot(erb_subbands[i, :].numpy())\n",
    "        plt.plot(erb_envs[i, :].numpy())\n",
    "        plt.show()\n",
    "\n",
    "fire_path = \"../sounds/fire_sounds/fire.wav\"\n",
    "sr = 44100\n",
    "fire_audio, _ = librosa.load(fire_path, sr=sr)\n",
    "#random integer from 0 to sample size\n",
    "lorea = np.random.randint(0, len(fire_audio)- 2**14)\n",
    "fire_audio = fire_audio[lorea : lorea+2**14]\n",
    "# Compute the envelope of the audio\n",
    "N_filter_bank = 16\n",
    "param_per_env = 256\n",
    "segment = torch.tensor(fire_audio, dtype=torch.float32)\n",
    "env_computer(segment, sr, N_filter_bank, param_per_env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIRE RESYNTHESIS --------------------------------------\n",
    "\n",
    "# Load audio to resynthesize ----------------------------\n",
    "fire_path = \"../sounds/fire_sounds/fire.wav\"\n",
    "sr = 44100\n",
    "fire_audio, _ = librosa.load(fire_path, sr=sr)\n",
    "\n",
    "print(\"max amplitude: \", np.max(np.abs(fire_audio)))\n",
    "\n",
    "# Make list of segments for fire and water --------------\n",
    "frame_size = 2**16 # 2**16 = 65536 correspond to around 1.5 seconds (quite long frames)\n",
    "hop_size = 2**16\n",
    "fire_segments = []\n",
    "\n",
    "for i in range(0, len(fire_audio) - frame_size, hop_size):\n",
    "    fire_segments.append(fire_audio[i:i + frame_size])\n",
    "\n",
    "# Seed creation -----------------------------------------\n",
    "N_filter_bank = 32 # This is a high number of filter (16 is the typical)\n",
    "seed = ddsp_textures.auxiliar.seeds.seed_maker(frame_size, 44100, N_filter_bank)\n",
    "\n",
    "# Run the resynthesizer for a bunch of fire and water segments\n",
    "param_per_env = 512  # 1024*24 = 2**13 * 3 => compression of (2**13 * 3)/2**16 = 3/8 ~ 0.375 \n",
    "resynthesize_and_display(fire_segments,  sr, seed, N_filter_bank, frame_size, param_per_env, \"Fire\",  5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WATER RESYNTHESIS --------------------------------------\n",
    "\n",
    "# Load audio to resynthesize ----------------------------\n",
    "water_path = \"../sounds/water_sounds/water.wav\"\n",
    "sr = 44100\n",
    "water_audio, _ = librosa.load(water_path, sr=sr)\n",
    "\n",
    "# Water segments ----------------------------------------\n",
    "frame_size = 2**16 # 2**14 corresponds to around 0.37 seconds (sort of short frames)\n",
    "hop_size   = 2**16\n",
    "water_segments = []\n",
    "\n",
    "for i in range(0, len(water_audio) - frame_size, hop_size):\n",
    "    water_segments.append(water_audio[i:i + frame_size])\n",
    "\n",
    "# Seed creation -----------------------------------------\n",
    "N_filter_bank = 32\n",
    "seed = ddsp_textures.auxiliar.seeds.seed_maker(frame_size, 44100, N_filter_bank)\n",
    "\n",
    "# Run the resynthesizer for a bunch of fire and water segments\n",
    "param_per_env = 2048  # 256*16 = 2**12 => compression of 2**12/2**14 = 1/4\n",
    "resynthesize_and_display(water_segments,  sr, seed, N_filter_bank, frame_size, param_per_env, \"Water\",  3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New resynthesis function using the stems functions\n",
    "def resynthesize_and_display_stems(segments, sr, seed, N_filter_bank, frame_size, param_per_env, label, N):\n",
    "    for _ in range(N):\n",
    "        # Select a random audio segment from the provided list\n",
    "        segment = segments[np.random.randint(len(segments))]\n",
    "        segment = torch.tensor(segment, dtype=torch.float32)\n",
    "\n",
    "        # Extract parameters (real and imaginary parts) for the envelope synthesis\n",
    "        param_real, param_imag = ddsp_textures.signal_processors.synthesizers.TexEnv_param_extractor(\n",
    "            segment, sr, N_filter_bank, param_per_env)\n",
    "\n",
    "        # Get the list of env_locals using the modified TexEnv function (stems)\n",
    "        env_locals = ddsp_textures.signal_processors.synthesizers.TexEnv_stems(param_real, param_imag, frame_size, N_filter_bank)\n",
    "\n",
    "        # Convert the env_locals back into a signal using env_locals_to_signal\n",
    "        new_audio = ddsp_textures.signal_processors.synthesizers.TexEnv_stems_to_signal(env_locals, seed)\n",
    "\n",
    "        # Display original and resynthesized audio\n",
    "        print(f\"{label} original audio\")\n",
    "        display(Audio(data=segment.numpy(), rate=sr))\n",
    "\n",
    "        print(f\"{label} resynthesized audio from stems\")\n",
    "        display(Audio(data=new_audio.numpy(), rate=sr))\n",
    "\n",
    "        new_audio_2 = ddsp_textures.signal_processors.synthesizers.TexEnv(param_real, param_imag, seed)\n",
    "\n",
    "        print(f\"{label} resynthesized audio from original function\")\n",
    "        display(Audio(data=new_audio_2.numpy(), rate=sr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WATER RESYNTHESIS --------------------------------------\n",
    "\n",
    "# Load audio to resynthesize ----------------------------\n",
    "water_path = \"../sounds/water_sounds/water_short.wav\"\n",
    "sr = 44100\n",
    "water_audio, _ = librosa.load(water_path, sr=sr)\n",
    "\n",
    "# Water segments ----------------------------------------\n",
    "frame_size = 2**16 # 2**14 corresponds to around 0.37 seconds (sort of short frames)\n",
    "hop_size = 2**16\n",
    "water_segments = []\n",
    "\n",
    "for i in range(0, len(water_audio) - frame_size, hop_size):\n",
    "    water_segments.append(water_audio[i:i + frame_size])\n",
    "\n",
    "# Seed creation -----------------------------------------\n",
    "N_filter_bank = 32\n",
    "seed = ddsp_textures.auxiliar.seeds.seed_maker(frame_size, 44100, N_filter_bank)\n",
    "\n",
    "# Run the resynthesizer for a bunch of fire and water segments\n",
    "param_per_env = 512  # 256*16 = 2**12 => compression of 2**12/2**14 = 1/4\n",
    "resynthesize_and_display_stems(water_segments,  sr, seed, N_filter_bank, frame_size, param_per_env, \"Water\",  3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dimensions check for stems functions -------------------\n",
    "\n",
    "# Load audio to resynthesize ----------------------------\n",
    "water_path = \"../sounds/water_sounds/water_short.wav\"\n",
    "sr = 44100\n",
    "water_audio, _ = librosa.load(water_path, sr=sr)\n",
    "\n",
    "# Water segments ----------------------------------------\n",
    "frame_size = 2**14 # 2**14 corresponds to around 0.37 seconds (sort of short frames)\n",
    "hop_size = 2**14\n",
    "water_segment = water_audio[10*frame_size:11*frame_size]\n",
    "water_segment_torch = torch.tensor(water_segment, dtype=torch.float32)\n",
    "# Seed creation -----------------------------------------\n",
    "N_filter_bank = 16\n",
    "seed = ddsp_textures.auxiliar.seeds.seed_maker(frame_size, 44100, N_filter_bank)\n",
    "\n",
    "# Run the resynthesizer for a bunch of fire and water segments\n",
    "param_per_env = 256  # 256*16 = 2**12 => compression of 2**12/2**14 = 1/4\n",
    "\n",
    "# Extract parameters (real and imaginary parts) for the envelope synthesis\n",
    "param_real, param_imag = ddsp_textures.signal_processors.synthesizers.TexEnv_param_extractor(water_segment_torch, sr, N_filter_bank, param_per_env)\n",
    "\n",
    "# print shapes\n",
    "print(\"param_real shape:\", param_real.shape)\n",
    "print(\"param_imag shape:\", param_imag.shape)\n",
    "\n",
    "env_locals = ddsp_textures.signal_processors.synthesizers.TexEnv_stems(param_real, param_imag, frame_size, N_filter_bank)\n",
    "\n",
    "print(\"env_locals length:\", len(env_locals))\n",
    "print(\"env_locals[0] shape:\", env_locals[0].shape)\n",
    "\n",
    "# plot all env_locals in one figure of 4x6 subplots with the same y-axis\n",
    "plt.figure(figsize=(30, 30))\n",
    "for i in range(len(env_locals)):\n",
    "    plt.subplot(4, 4, i+1)\n",
    "    plt.ylim(0, 0.05)\n",
    "    plt.plot(env_locals[i])\n",
    "    plt.title(f\"env_local {i}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dimensions check for stems functions -------------------\n",
    "\n",
    "# Load audio to resynthesize ----------------------------\n",
    "water_path = \"../sounds/water_sounds/water_short.wav\"\n",
    "sr = 44100\n",
    "water_audio, _ = librosa.load(water_path, sr=sr)\n",
    "\n",
    "# Water segments ----------------------------------------\n",
    "frame_size = 2**14 # 2**14 corresponds to around 0.37 seconds (sort of short frames)\n",
    "hop_size = 2**14\n",
    "water_segments = []\n",
    "\n",
    "# make batch of L segments\n",
    "L = 16\n",
    "for i in range(0, L):\n",
    "    segment_local = water_audio[i*hop_size:i*hop_size + frame_size]\n",
    "    segment_local_torch = torch.tensor(segment_local, dtype=torch.float32)\n",
    "    water_segments.append(segment_local_torch)\n",
    "\n",
    "#water segments to batch\n",
    "water_segment_torch = torch.stack(water_segments)\n",
    "print(\"(batch) water_segment_torch shape:\", water_segment_torch.shape)\n",
    "\n",
    "# Seed creation -----------------------------------------\n",
    "N_filter_bank = 24\n",
    "seed = ddsp_textures.auxiliar.seeds.seed_maker(frame_size, 44100, N_filter_bank)\n",
    "\n",
    "# Run the resynthesizer for a bunch of fire and water segments\n",
    "param_per_env = 512  # 256*16 = 2**12 => compression of 2**12/2**14 = 1/4\n",
    "\n",
    "# Extract parameters (real and imaginary parts) for each segment in the batch and make a new batch of parameters\n",
    "param_real = []\n",
    "param_imag = []\n",
    "for i in range(0, L):\n",
    "    segment_local = water_segment_torch[i]\n",
    "    param_real_local, param_imag_local = ddsp_textures.signal_processors.synthesizers.TexEnv_param_extractor(segment_local, sr, N_filter_bank, param_per_env)\n",
    "    param_real.append(param_real_local)\n",
    "    param_imag.append(param_imag_local)\n",
    "\n",
    "#Make batches of parameters\n",
    "param_real = torch.stack(param_real)\n",
    "param_imag = torch.stack(param_imag)\n",
    "\n",
    "# print shapes\n",
    "print(\"(batch) param_real shape:\", param_real.shape)\n",
    "print(\"(batch) param_imag shape:\", param_imag.shape)\n",
    "\n",
    "env_locals_batches = ddsp_textures.signal_processors.synthesizers.TexEnv_stems_batches(param_real, param_imag, frame_size, N_filter_bank)\n",
    "\n",
    "#print shape\n",
    "print(\"env_locals_batches shape:\", env_locals_batches.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_batches = ddsp_textures.signal_processors.synthesizers.TexEnv_stems_to_signals_batches(env_locals_batches, seed, target_loudness=1)\n",
    "print(\"results_batches shape:\", results_batches.shape)\n",
    "\n",
    "# play each sound in the batch together with its original version\n",
    "for i in range(0, L):\n",
    "    print(f\"original audio {i}\")\n",
    "    display(Audio(data=water_segment_torch[i].numpy(), rate=sr))\n",
    "    print(f\"resynthesized audio {i}\")\n",
    "    display(Audio(data=results_batches[i].numpy(), rate=sr))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_ddsp_textures",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
