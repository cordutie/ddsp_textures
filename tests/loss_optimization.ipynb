{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the parent directory to the Python path\n",
    "parent_dir = os.path.abspath('../..')\n",
    "if parent_dir not in sys.path:\n",
    "    sys.path.append(parent_dir)\n",
    "\n",
    "from ddsp_textures.dataset.makers    import read_wavs_from_folder\n",
    "from ddsp_textures.auxiliar.features import *\n",
    "\n",
    "audio_path    = \"../sounds/loss_optimization_dataset\"\n",
    "sampling_rate = 44100\n",
    "frame_size    = 2**16\n",
    "hop_size      = 2**15\n",
    "audios_list   = read_wavs_from_folder(audio_path, sampling_rate)\n",
    "data          = []\n",
    "\n",
    "j = 0\n",
    "for audio in audios_list:\n",
    "    size = len(audio)\n",
    "    number_of_segments = (size - frame_size) // hop_size\n",
    "    number_of_segments = number_of_segments if number_of_segments < 256 else 256\n",
    "    for i in range(number_of_segments):\n",
    "        segment = audio[i * hop_size : i * hop_size + frame_size]\n",
    "        segment = audio_improver(segment, sampling_rate, 4)\n",
    "        segment = signal_normalizer(segment)\n",
    "        data.append([segment, torch.tensor(j)])\n",
    "    j += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 100%|██████████| 128/128 [09:07<00:00,  4.28s/batch, batch_loss=-88.6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: -20414.9560\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10: 100%|██████████| 128/128 [09:06<00:00,  4.27s/batch, batch_loss=-1.01e+3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10, Loss: -128963.3793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10: 100%|██████████| 128/128 [09:07<00:00,  4.28s/batch, batch_loss=-93]     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10, Loss: -161573.2984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10: 100%|██████████| 128/128 [09:09<00:00,  4.29s/batch, batch_loss=-1.18e+3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10, Loss: -163912.9622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10: 100%|██████████| 128/128 [09:07<00:00,  4.27s/batch, batch_loss=-2.42e+3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10, Loss: -180718.0450\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10: 100%|██████████| 128/128 [09:06<00:00,  4.27s/batch, batch_loss=-2.77e+3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10, Loss: -174318.3100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10: 100%|██████████| 128/128 [09:09<00:00,  4.30s/batch, batch_loss=-1.38e+3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10, Loss: -174834.5464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10: 100%|██████████| 128/128 [09:06<00:00,  4.27s/batch, batch_loss=-403]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10, Loss: -180187.6891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10: 100%|██████████| 128/128 [09:09<00:00,  4.29s/batch, batch_loss=-1.51e+3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10, Loss: -171309.1865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|██████████| 128/128 [09:08<00:00,  4.28s/batch, batch_loss=-920]    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10, Loss: -173425.0385\n",
      "Optimized Parameters: tensor([3.4230e-04, 1.7296e-04, 1.3878e-03, 9.9564e-01, 7.8497e-04, 3.8259e-04,\n",
      "        1.3160e-04, 1.1537e-03], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from ddsp_textures.loss.functions import *\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Set device to GPU if available, else use CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)\n",
    "\n",
    "# Define constants (replace these with actual values)\n",
    "N_filter_bank = 32\n",
    "M_filter_bank = 24\n",
    "erb_bank = ddsp_textures.auxiliar.filterbanks.EqualRectangularBandwidth(frame_size, sampling_rate, N_filter_bank, 20, sampling_rate // 2)\n",
    "new_frame_size = frame_size // 4\n",
    "new_sampling_rate = sampling_rate // 4\n",
    "log_bank = ddsp_textures.auxiliar.filterbanks.Logarithmic(new_frame_size, new_sampling_rate, M_filter_bank, 10, new_sampling_rate // 4)\n",
    "downsampler = torchaudio.transforms.Resample(sampling_rate, new_sampling_rate).to(device)\n",
    "\n",
    "# Convert data into tensors if necessary\n",
    "signals    = [item[0] for item in data]\n",
    "categories = [item[1] for item in data]\n",
    "\n",
    "# Move data to the appropriate device (GPU or CPU)\n",
    "signals_tensor = torch.stack(signals).to(device)\n",
    "categories_tensor = torch.stack(categories).to(device)\n",
    "\n",
    "# Create a DataLoader for batching\n",
    "batch_size = 8  # Choose a batch size based on available memory\n",
    "dataset = TensorDataset(signals_tensor, categories_tensor)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Initialize alpha with random values and move it to the device\n",
    "alpha = torch.randn(8, requires_grad=True, device=device)\n",
    "\n",
    "# Optimizer\n",
    "optimizer = torch.optim.Adam([alpha], lr=0.01)\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0\n",
    "    \n",
    "    # Use tqdm to show progress for each epoch\n",
    "    with tqdm(dataloader, desc=f\"Epoch {epoch+1}/{num_epochs}\", unit=\"batch\") as pbar:\n",
    "        for batch in pbar:\n",
    "            batch_signals, batch_categories = batch\n",
    "\n",
    "            # Move batch data to device\n",
    "            batch_signals    = batch_signals.to(device)\n",
    "            batch_categories = batch_categories.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Apply softmax to ensure sum constraint on alpha\n",
    "            normalized_alpha = torch.softmax(alpha, dim=0)\n",
    "\n",
    "            # Calculate loss within the batch\n",
    "            batch_loss = 0\n",
    "            batch_size = len(batch_signals)\n",
    "\n",
    "            for i in range(batch_size):\n",
    "                for j in range(i + 1, batch_size):\n",
    "                    signal_1, category_1 = batch_signals[i], batch_categories[i]\n",
    "                    signal_2, category_2 = batch_signals[j], batch_categories[j]\n",
    "\n",
    "                    # Calculate loss using batch_statistics_loss\n",
    "                    if category_1 == category_2:\n",
    "                        # Minimize distance for same class\n",
    "                        batch_loss += statistics_loss(\n",
    "                            signal_1, signal_2, N_filter_bank, M_filter_bank,\n",
    "                            erb_bank, log_bank, downsampler, normalized_alpha\n",
    "                        )\n",
    "                    else:\n",
    "                        # Maximize distance for different classes\n",
    "                        batch_loss -= statistics_loss(\n",
    "                            signal_1, signal_2, N_filter_bank, M_filter_bank,\n",
    "                            erb_bank, log_bank, downsampler, normalized_alpha\n",
    "                        )\n",
    "\n",
    "            # Backpropagate and optimize\n",
    "            batch_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Track total loss for reporting\n",
    "            total_loss += batch_loss.item()\n",
    "\n",
    "            # Update tqdm description (optional, if you want to print batch-level progress)\n",
    "            pbar.set_postfix(batch_loss=batch_loss.item())\n",
    "\n",
    "    # Print the total loss at the end of each epoch\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {total_loss:.4f}\")\n",
    "\n",
    "# Final optimized parameters\n",
    "final_alpha = torch.softmax(alpha, dim=0).detach()\n",
    "print(\"Optimized Parameters:\", final_alpha)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the optimized parameters to a file\n",
    "torch.save(final_alpha, \"optimized_parameters_v1.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 100%|██████████| 128/128 [09:08<00:00,  4.28s/batch, batch_loss=74.4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 9369.0780\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10: 100%|██████████| 128/128 [09:05<00:00,  4.26s/batch, batch_loss=28.1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10, Loss: 4631.9188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10: 100%|██████████| 128/128 [09:05<00:00,  4.26s/batch, batch_loss=47.6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10, Loss: 4225.0310\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10: 100%|██████████| 128/128 [09:06<00:00,  4.27s/batch, batch_loss=40.4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10, Loss: 4181.0420\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10: 100%|██████████| 128/128 [09:05<00:00,  4.26s/batch, batch_loss=22.7]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10, Loss: 3826.9369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10: 100%|██████████| 128/128 [09:06<00:00,  4.27s/batch, batch_loss=24.9]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10, Loss: 3769.4456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10: 100%|██████████| 128/128 [09:06<00:00,  4.27s/batch, batch_loss=30]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10, Loss: 3595.0089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10: 100%|██████████| 128/128 [09:04<00:00,  4.26s/batch, batch_loss=29.3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10, Loss: 3443.7540\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10: 100%|██████████| 128/128 [09:06<00:00,  4.27s/batch, batch_loss=28.3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10, Loss: 3345.5898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|██████████| 128/128 [09:06<00:00,  4.27s/batch, batch_loss=24.5]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10, Loss: 3428.0847\n",
      "Optimized Parameters: tensor([0.0070, 0.0035, 0.8993, 0.0049, 0.0431, 0.0265, 0.0067, 0.0089],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from ddsp_textures.loss.functions import *\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Set device to GPU if available, else use CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)\n",
    "\n",
    "# Define constants (replace these with actual values)\n",
    "N_filter_bank = 32\n",
    "M_filter_bank = 24\n",
    "erb_bank = ddsp_textures.auxiliar.filterbanks.EqualRectangularBandwidth(frame_size, sampling_rate, N_filter_bank, 20, sampling_rate // 2)\n",
    "new_frame_size = frame_size // 4\n",
    "new_sampling_rate = sampling_rate // 4\n",
    "log_bank = ddsp_textures.auxiliar.filterbanks.Logarithmic(new_frame_size, new_sampling_rate, M_filter_bank, 10, new_sampling_rate // 4)\n",
    "downsampler = torchaudio.transforms.Resample(sampling_rate, new_sampling_rate).to(device)\n",
    "\n",
    "# Convert data into tensors if necessary\n",
    "signals    = [item[0] for item in data]\n",
    "categories = [item[1] for item in data]\n",
    "\n",
    "# Move data to the appropriate device (GPU or CPU)\n",
    "signals_tensor = torch.stack(signals).to(device)\n",
    "categories_tensor = torch.stack(categories).to(device)\n",
    "\n",
    "# Create a DataLoader for batching\n",
    "batch_size = 8  # Choose a batch size based on available memory\n",
    "dataset = TensorDataset(signals_tensor, categories_tensor)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Initialize alpha with random values and move it to the device\n",
    "alpha = torch.randn(8, requires_grad=True, device=device)\n",
    "\n",
    "# Optimizer\n",
    "optimizer = torch.optim.Adam([alpha], lr=0.01)\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0\n",
    "    \n",
    "    # Use tqdm to show progress for each epoch\n",
    "    with tqdm(dataloader, desc=f\"Epoch {epoch+1}/{num_epochs}\", unit=\"batch\") as pbar:\n",
    "        for batch in pbar:\n",
    "            batch_signals, batch_categories = batch\n",
    "\n",
    "            # Move batch data to device\n",
    "            batch_signals    = batch_signals.to(device)\n",
    "            batch_categories = batch_categories.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Apply softmax to ensure sum constraint on alpha\n",
    "            normalized_alpha = torch.softmax(alpha, dim=0)\n",
    "\n",
    "            # Calculate loss within the batch\n",
    "            batch_loss = 0\n",
    "            batch_size = len(batch_signals)\n",
    "\n",
    "            for i in range(batch_size):\n",
    "                for j in range(i + 1, batch_size):\n",
    "                    signal_1, category_1 = batch_signals[i], batch_categories[i]\n",
    "                    signal_2, category_2 = batch_signals[j], batch_categories[j]\n",
    "\n",
    "                    # Calculate loss using batch_statistics_loss\n",
    "                    if category_1 == category_2:\n",
    "                        # Minimize distance for same class\n",
    "                        batch_loss += statistics_loss(\n",
    "                            signal_1, signal_2, N_filter_bank, M_filter_bank,\n",
    "                            erb_bank, log_bank, downsampler, normalized_alpha\n",
    "                        )\n",
    "                    else:\n",
    "                        # Maximize distance for different classes\n",
    "                        batch_loss += 1/statistics_loss(\n",
    "                            signal_1, signal_2, N_filter_bank, M_filter_bank,\n",
    "                            erb_bank, log_bank, downsampler, normalized_alpha\n",
    "                        )\n",
    "\n",
    "            # Backpropagate and optimize\n",
    "            batch_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Track total loss for reporting\n",
    "            total_loss += batch_loss.item()\n",
    "\n",
    "            # Update tqdm description (optional, if you want to print batch-level progress)\n",
    "            pbar.set_postfix(batch_loss=batch_loss.item())\n",
    "\n",
    "    # Print the total loss at the end of each epoch\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {total_loss:.4f}\")\n",
    "\n",
    "# Final optimized parameters\n",
    "final_alpha = torch.softmax(alpha, dim=0).detach()\n",
    "print(\"Optimized Parameters:\", final_alpha)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the optimized parameters to a file\n",
    "torch.save(final_alpha, \"optimized_parameters_v2.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_ddsp_textures",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
